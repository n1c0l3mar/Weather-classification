{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Preliminary Model**\n",
        "###**Updated Version, New Load In**"
      ],
      "metadata": {
        "id": "rJP1FSE4ZRYR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets, transforms, models\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import random\n",
        "import shutil\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib.image import imread\n",
        "import os\n",
        "from imageio import imread\n",
        "\n",
        "# Stop warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "WoWcpnDjZaZ0"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "#!unzip /content/drive/MyDrive/dataset.zip -d /content/dataset\n",
        "#path = '/content/dataset/dataset'"
      ],
      "metadata": {
        "id": "5ag2BZR5Zf-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "width = []\n",
        "height = []\n",
        "channel_color = []\n",
        "weather_type = []\n",
        "\n",
        "path = '/content/dataset/dataset'\n",
        "\n",
        "# for each subfolder (category)\n",
        "for folder in os.listdir(path):\n",
        "    subfolder_path = os.path.join(path, folder_name)\n",
        "\n",
        "    # skip if not a directory\n",
        "    if not os.path.isdir(subfolder_path):\n",
        "        continue\n",
        "\n",
        "    for image_file in os.listdir(subfolder_path):\n",
        "        image_path = os.path.join(subfolder_path, image_file)\n",
        "\n",
        "        # skip directories inside category folders\n",
        "        if os.path.isdir(image_path):\n",
        "            continue\n",
        "\n",
        "        image = imread(image_path)\n",
        "\n",
        "        # handle grayscale images\n",
        "        if len(image.shape) < 3:\n",
        "            image = image.reshape(image.shape + (1,))\n",
        "\n",
        "        height, width, channel = image.shape\n",
        "        width.append(width)      # width on x-axis\n",
        "        height.append(height)     # height on y-axis\n",
        "        channel_color.append(channel)\n",
        "        weather_type.append(folder_name)  # use folder name as label\n",
        "\n",
        "# create DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'width': width,\n",
        "    'height': height,\n",
        "    'channels': channel_color,\n",
        "    'weather': weather_type\n",
        "})\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "S7PDK4amZ025"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(dim1)"
      ],
      "metadata": {
        "id": "SUxS8sZ9Z3iD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(dim2)"
      ],
      "metadata": {
        "id": "_vqa39UgZ5eD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5,0.5,0.5], std=[0.5,0.5,0.5])\n",
        "])\n",
        "\n",
        "# Correct root folder\n",
        "dataset = datasets.ImageFolder('/content/dataset/dataset', transform=transform)\n",
        "\n",
        "print(\"Classes:\", dataset.classes)"
      ],
      "metadata": {
        "id": "SX5qNQGEZ7xs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import random_split, DataLoader\n",
        "from collections import Counter\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# Transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),   # resize images\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "# Load dataset\n",
        "dataset = datasets.ImageFolder('/content/dataset/dataset', transform=transform)\n",
        "num_classes = len(dataset.classes)\n",
        "print(\"Classes:\", dataset.classes)\n",
        "\n",
        "# Optional: check number of images per class\n",
        "labels = [label for _, label in dataset]\n",
        "counts = Counter(labels)\n",
        "print(\"Images per class:\", counts)\n",
        "\n",
        "# Train/Validation split\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32)\n",
        "\n",
        "\n",
        "# Define CNN\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
        "        self.fc1 = nn.Linear(32 * 16 * 16, 128)\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 32 * 16 * 16)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = SimpleCNN(num_classes).to(device)\n",
        "\n",
        "# Loss & optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "# Training loop\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}\")\n",
        "\n",
        "# Validation\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in val_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(\"Validation Accuracy: {:.2f}%\".format(100 * correct / total))"
      ],
      "metadata": {
        "id": "DQMhcq1QZ8gt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Graphics"
      ],
      "metadata": {
        "id": "jVHJSFv3aBlE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "all_labels = []\n",
        "all_preds = []\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for images, labels in val_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "        all_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "sns.heatmap(cm, annot=True, fmt='d', xticklabels=dataset.classes, yticklabels=dataset.classes)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Vic51Wl_aGC5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}