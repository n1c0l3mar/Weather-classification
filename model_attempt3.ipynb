{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8bAJea5bESw"
      },
      "source": [
        "**Model Attempt #3**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHRZ8X79cCYl"
      },
      "source": [
        "Improvments To Be Made:\n",
        "\n",
        "Image size- 224Ã—224 (ResNet)\n",
        "\n",
        "Min data aug- flip/rotate\n",
        "\n",
        "Fix Class imbalance w/ weighted loss\n",
        "\n",
        "Early stopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hh7_JFckdLqK"
      },
      "outputs": [],
      "source": [
        "#libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets, transforms, models\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import random\n",
        "import shutil\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib.image import imread\n",
        "import os\n",
        "from imageio import imread\n",
        "\n",
        "#Stop warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "#!unzip /content/drive/MyDrive/dataset.zip -d /content/dataset\n",
        "#path = '/content/dataset/dataset'\n",
        "path = './dataset' # adjust path as needed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "10_2HxytdMD4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>width</th>\n",
              "      <th>height</th>\n",
              "      <th>channels</th>\n",
              "      <th>weather</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>283</td>\n",
              "      <td>400</td>\n",
              "      <td>3</td>\n",
              "      <td>lightning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>300</td>\n",
              "      <td>400</td>\n",
              "      <td>3</td>\n",
              "      <td>lightning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>264</td>\n",
              "      <td>400</td>\n",
              "      <td>3</td>\n",
              "      <td>lightning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>188</td>\n",
              "      <td>378</td>\n",
              "      <td>3</td>\n",
              "      <td>lightning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>238</td>\n",
              "      <td>284</td>\n",
              "      <td>3</td>\n",
              "      <td>lightning</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   width  height  channels    weather\n",
              "0    283     400         3  lightning\n",
              "1    300     400         3  lightning\n",
              "2    264     400         3  lightning\n",
              "3    188     378         3  lightning\n",
              "4    238     284         3  lightning"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load data\n",
        "width = []\n",
        "height = []\n",
        "channel_color = []\n",
        "weather_type = []\n",
        "\n",
        "path = './dataset' # adjust path as needed\n",
        "\n",
        "for folder in os.listdir(path):\n",
        "    subfolder_path = os.path.join(path, folder)\n",
        "\n",
        "    if not os.path.isdir(subfolder_path):\n",
        "        continue\n",
        "\n",
        "    for image_file in os.listdir(subfolder_path):\n",
        "        image_path = os.path.join(subfolder_path, image_file)\n",
        "\n",
        "        if os.path.isdir(image_path):\n",
        "            continue\n",
        "\n",
        "        image = imread(image_path)\n",
        "\n",
        "        if len(image.shape) < 3:\n",
        "            image = image.reshape(image.shape + (1,))\n",
        "\n",
        "        h, w, c = image.shape\n",
        "        width.append(h)      \n",
        "        height.append(w)     \n",
        "        channel_color.append(c)\n",
        "        weather_type.append(folder)   \n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'width': width,\n",
        "    'height': height,\n",
        "    'channels': channel_color,\n",
        "    'weather': weather_type\n",
        "})\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESaS8eW_dPaG"
      },
      "source": [
        "Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "3eeRzrdCcusY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n",
            "Classes: ['dew', 'fogsmog', 'frost', 'glaze', 'hail', 'lightning', 'rain', 'rainbow', 'rime', 'sandstorm', 'snow']\n",
            "Epoch 1/15, Train Loss: 1.1409, Val Loss: 0.6814, Val Acc: 79.53%\n",
            "Epoch 2/15, Train Loss: 0.5919, Val Loss: 0.5344, Val Acc: 81.79%\n",
            "Epoch 3/15, Train Loss: 0.4990, Val Loss: 0.4767, Val Acc: 84.12%\n",
            "Epoch 4/15, Train Loss: 0.4322, Val Loss: 0.4537, Val Acc: 84.05%\n",
            "Epoch 5/15, Train Loss: 0.4035, Val Loss: 0.4277, Val Acc: 85.65%\n",
            "Epoch 6/15, Train Loss: 0.3738, Val Loss: 0.4275, Val Acc: 84.49%\n",
            "Epoch 7/15, Train Loss: 0.3533, Val Loss: 0.4239, Val Acc: 84.20%\n",
            "Epoch 8/15, Train Loss: 0.3394, Val Loss: 0.4041, Val Acc: 85.87%\n",
            "Epoch 9/15, Train Loss: 0.3252, Val Loss: 0.4047, Val Acc: 86.23%\n",
            "Epoch 10/15, Train Loss: 0.3152, Val Loss: 0.4021, Val Acc: 86.53%\n",
            "Epoch 11/15, Train Loss: 0.3120, Val Loss: 0.3958, Val Acc: 86.38%\n",
            "Epoch 12/15, Train Loss: 0.2991, Val Loss: 0.3964, Val Acc: 86.82%\n",
            "Epoch 13/15, Train Loss: 0.2925, Val Loss: 0.4073, Val Acc: 85.14%\n",
            "Epoch 14/15, Train Loss: 0.2772, Val Loss: 0.4006, Val Acc: 86.53%\n",
            "Epoch 15/15, Train Loss: 0.2800, Val Loss: 0.3988, Val Acc: 87.40%\n",
            "Best Validation Accuracy: 87.40%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "from collections import Counter\n",
        "import copy\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "#Data augmentation\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],   # pretrained ImageNet mean/std\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "transform_val = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "dataset = datasets.ImageFolder('./dataset', transform=transform_train) #adjust path as needed\n",
        "num_classes = len(dataset.classes)\n",
        "print(\"Classes:\", dataset.classes)\n",
        "\n",
        "labels = [label for _, label in dataset]\n",
        "counts = Counter(labels)\n",
        "\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "\n",
        "val_dataset.dataset.transform = transform_val\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32)\n",
        "\n",
        "#Loading pretrained ResNet18\n",
        "model = models.resnet18(pretrained=True)\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "model = model.to(device)\n",
        "\n",
        "class_counts = torch.tensor([counts[i] for i in range(num_classes)], dtype=torch.float)\n",
        "class_weights = 1.0 / class_counts\n",
        "class_weights = class_weights / class_weights.sum() * num_classes  # normalize\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
        "\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=1e-3)\n",
        "\n",
        "#Training loop with early stopping\n",
        "epochs = 15\n",
        "best_val_acc = 0\n",
        "best_model_wts = copy.deepcopy(model.state_dict())\n",
        "patience_counter = 0\n",
        "early_stop_patience = 4\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "    avg_train_loss = running_loss / len(train_loader)\n",
        "\n",
        "    #Validation\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "    val_acc = 100 * correct / total\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
        "\n",
        "    #Early stopping\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        best_model_wts = copy.deepcopy(model.state_dict())\n",
        "        patience_counter = 0\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= early_stop_patience:\n",
        "            print(\"Early stopping triggered\")\n",
        "            break\n",
        "\n",
        "model.load_state_dict(best_model_wts)\n",
        "print(f\"Best Validation Accuracy: {best_val_acc:.2f}%\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "weather-classification",
      "language": "python",
      "name": "weather-classification"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
