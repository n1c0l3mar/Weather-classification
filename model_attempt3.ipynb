{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Model Attempt #3**"
      ],
      "metadata": {
        "id": "B8bAJea5bESw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Improvments To Be Made:\n",
        "\n",
        "Image size- 224Ã—224 (ResNet)\n",
        "\n",
        "Min data aug- flip/rotate\n",
        "\n",
        "Fix Class imbalance w/ weighted loss\n",
        "\n",
        "Early stopping"
      ],
      "metadata": {
        "id": "KHRZ8X79cCYl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets, transforms, models\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import random\n",
        "import shutil\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib.image import imread\n",
        "import os\n",
        "from imageio import imread\n",
        "\n",
        "# Stop warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "#!unzip /content/drive/MyDrive/dataset.zip -d /content/dataset\n",
        "#path = '/content/dataset/dataset'\n"
      ],
      "metadata": {
        "id": "hh7_JFckdLqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "width = []\n",
        "height = []\n",
        "channel_color = []\n",
        "weather_type = []\n",
        "\n",
        "path = '/content/dataset/dataset'\n",
        "\n",
        "# for each subfolder (category)\n",
        "for folder in os.listdir(path):\n",
        "    subfolder_path = os.path.join(path, folder_name)\n",
        "\n",
        "    # skip if not a directory\n",
        "    if not os.path.isdir(subfolder_path):\n",
        "        continue\n",
        "\n",
        "    for image_file in os.listdir(subfolder_path):\n",
        "        image_path = os.path.join(subfolder_path, image_file)\n",
        "\n",
        "        # skip directories inside category folders\n",
        "        if os.path.isdir(image_path):\n",
        "            continue\n",
        "\n",
        "        image = imread(image_path)\n",
        "\n",
        "        # handle grayscale images\n",
        "        if len(image.shape) < 3:\n",
        "            image = image.reshape(image.shape + (1,))\n",
        "\n",
        "        height, width, channel = image.shape\n",
        "        width.append(width)      # width on x-axis\n",
        "        height.append(height)     # height on y-axis\n",
        "        channel_color.append(channel)\n",
        "        weather_type.append(folder_name)  # use folder name as label\n",
        "\n",
        "# create DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'width': width,\n",
        "    'height': height,\n",
        "    'channels': channel_color,\n",
        "    'weather': weather_type\n",
        "})\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "10_2HxytdMD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model"
      ],
      "metadata": {
        "id": "ESaS8eW_dPaG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "from collections import Counter\n",
        "import copy\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# Data augmentation and transforms\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],   # pretrained ImageNet mean/std\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "transform_val = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load dataset\n",
        "dataset = datasets.ImageFolder('/content/dataset/dataset', transform=transform_train)\n",
        "num_classes = len(dataset.classes)\n",
        "print(\"Classes:\", dataset.classes)\n",
        "\n",
        "# Optional: check class distribution\n",
        "labels = [label for _, label in dataset]\n",
        "counts = Counter(labels)\n",
        "print(\"Images per class:\", counts)\n",
        "\n",
        "# Train/Validation split\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "\n",
        "# Override val dataset transforms\n",
        "val_dataset.dataset.transform = transform_val\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32)\n",
        "\n",
        "#Load pretrained ResNet18\n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "# Freeze early layers\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Replace classifier (fc) layer\n",
        "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "model = model.to(device)\n",
        "\n",
        "# Weighted loss for class imbalance\n",
        "class_counts = torch.tensor([counts[i] for i in range(num_classes)], dtype=torch.float)\n",
        "class_weights = 1.0 / class_counts\n",
        "class_weights = class_weights / class_weights.sum() * num_classes  # normalize\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=1e-3)\n",
        "\n",
        "# Training loop with early stopping\n",
        "epochs = 15\n",
        "best_val_acc = 0\n",
        "best_model_wts = copy.deepcopy(model.state_dict())\n",
        "patience_counter = 0\n",
        "early_stop_patience = 4\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # Training\n",
        "    model.train()\n",
        "    running_loss = 0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "    avg_train_loss = running_loss / len(train_loader)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "    val_acc = 100 * correct / total\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
        "\n",
        "    # Early stopping\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        best_model_wts = copy.deepcopy(model.state_dict())\n",
        "        patience_counter = 0\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= early_stop_patience:\n",
        "            print(\"Early stopping triggered\")\n",
        "            break\n",
        "\n",
        "# Load best weights\n",
        "model.load_state_dict(best_model_wts)\n",
        "print(f\"Best Validation Accuracy: {best_val_acc:.2f}%\")"
      ],
      "metadata": {
        "id": "3eeRzrdCcusY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}