{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XA59Ew7FaYdj"
      },
      "source": [
        "#**Model Attempt #2**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2AR2nZiaf-w"
      },
      "source": [
        "Improvments To Be Made:\n",
        "\n",
        "Data Augmentation- RandomHorizontalFlip, RandomRotation, ColorJitter\n",
        "\n",
        "Make Image BIGGER- 64×64 to 128×128\n",
        "\n",
        "CNN Update- Add BatchNorm2d after conv layers\n",
        "\n",
        "Dropout- added 0.5 before final fully connected layer\n",
        "\n",
        "Learning Rate Scheduler- ReduceLROnPlateau\n",
        "\n",
        "Lengthen Training and Early Stopping- stop if no improvement in 5 epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvjysLNQc4kV",
        "outputId": "7c00dcee-377b-431a-e4d3-2cdd80b4c516"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets, transforms, models\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import random\n",
        "import shutil\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib.image import imread\n",
        "import os\n",
        "from imageio import imread\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "#!unzip /content/drive/MyDrive/dataset.zip -d /content/dataset\n",
        "#path = '/content/dataset/dataset'\n",
        "path = './dataset'  # Update this path as needed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "pafmJFEI4Mot",
        "outputId": "e2956f75-e8ed-4f1f-99b1-6d1c4b74719f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>width</th>\n",
              "      <th>height</th>\n",
              "      <th>channels</th>\n",
              "      <th>weather</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>400</td>\n",
              "      <td>283</td>\n",
              "      <td>3</td>\n",
              "      <td>lightning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>400</td>\n",
              "      <td>300</td>\n",
              "      <td>3</td>\n",
              "      <td>lightning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>400</td>\n",
              "      <td>264</td>\n",
              "      <td>3</td>\n",
              "      <td>lightning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>378</td>\n",
              "      <td>188</td>\n",
              "      <td>3</td>\n",
              "      <td>lightning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>284</td>\n",
              "      <td>238</td>\n",
              "      <td>3</td>\n",
              "      <td>lightning</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   width  height  channels    weather\n",
              "0    400     283         3  lightning\n",
              "1    400     300         3  lightning\n",
              "2    400     264         3  lightning\n",
              "3    378     188         3  lightning\n",
              "4    284     238         3  lightning"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#initialize\n",
        "width = []\n",
        "height = []\n",
        "channel_color = []\n",
        "weather_type = []\n",
        "\n",
        "#set up path\n",
        "for folder in os.listdir(path):\n",
        "    subfolder_path = os.path.join(path, folder)\n",
        "\n",
        "    for image_file in os.listdir(subfolder_path):\n",
        "        image_path = os.path.join(subfolder_path, image_file)\n",
        "\n",
        "        image = imread(image_path)\n",
        "\n",
        "        if len(image.shape) < 3:\n",
        "            image = image.reshape(image.shape + (1,))\n",
        "\n",
        "        h, w, c = image.shape\n",
        "\n",
        "        #update lists\n",
        "        width.append(w)\n",
        "        height.append(h)\n",
        "        channel_color.append(c)\n",
        "        weather_type.append(folder)\n",
        "\n",
        "#make lists a df\n",
        "df = pd.DataFrame({'width': width, 'height': height, 'channels': channel_color, 'weather': weather_type})\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzQrlHzxdF8i"
      },
      "source": [
        "# **Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e17Lb_wLagkk",
        "outputId": "7140315b-3828-4eec-c2e0-d2225cc15b82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n",
            "Classes: ['dew', 'fogsmog', 'frost', 'glaze', 'hail', 'lightning', 'rain', 'rainbow', 'rime', 'sandstorm', 'snow']\n",
            "Epoch 1/20 | Train Loss: 2.3866 | Val Loss: 1.7558 | Val Acc: 45.81%\n",
            "Current LR: 0.001\n",
            "Epoch 2/20 | Train Loss: 1.9474 | Val Loss: 1.6676 | Val Acc: 50.11%\n",
            "Current LR: 0.001\n",
            "Epoch 3/20 | Train Loss: 1.8729 | Val Loss: 1.5059 | Val Acc: 52.59%\n",
            "Current LR: 0.001\n",
            "Epoch 4/20 | Train Loss: 1.7934 | Val Loss: 1.3708 | Val Acc: 51.86%\n",
            "Current LR: 0.001\n",
            "Epoch 5/20 | Train Loss: 1.7775 | Val Loss: 1.3516 | Val Acc: 54.12%\n",
            "Current LR: 0.001\n",
            "Epoch 6/20 | Train Loss: 1.7367 | Val Loss: 1.3777 | Val Acc: 53.75%\n",
            "Current LR: 0.001\n",
            "Epoch 7/20 | Train Loss: 1.6959 | Val Loss: 1.3059 | Val Acc: 56.96%\n",
            "Current LR: 0.001\n",
            "Epoch 8/20 | Train Loss: 1.6929 | Val Loss: 1.3620 | Val Acc: 53.53%\n",
            "Current LR: 0.001\n",
            "Epoch 9/20 | Train Loss: 1.6714 | Val Loss: 1.2646 | Val Acc: 55.94%\n",
            "Current LR: 0.001\n",
            "Epoch 10/20 | Train Loss: 1.6474 | Val Loss: 1.2517 | Val Acc: 56.88%\n",
            "Current LR: 0.001\n",
            "Epoch 11/20 | Train Loss: 1.6545 | Val Loss: 1.3367 | Val Acc: 56.88%\n",
            "Current LR: 0.001\n",
            "Epoch 12/20 | Train Loss: 1.6249 | Val Loss: 1.2737 | Val Acc: 56.15%\n",
            "Current LR: 0.001\n",
            "Early stopping triggered\n",
            "Best Validation Accuracy: 56.96%\n"
          ]
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "from collections import Counter\n",
        "import copy\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5,0.5,0.5], std=[0.5,0.5,0.5])\n",
        "])\n",
        "\n",
        "\n",
        "dataset = datasets.ImageFolder('./dataset', transform=transform) #Set to your correct dataset path!!\n",
        "num_classes = len(dataset.classes)\n",
        "print(\"Classes:\", dataset.classes)\n",
        "\n",
        "\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32)\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(32)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc1 = nn.Linear(32 * 32 * 32, 128)\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "        x = x.view(-1, 32 * 32 * 32)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = SimpleCNN(num_classes).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "train_losses = []\n",
        "\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
        "\n",
        "epochs = 20\n",
        "best_val_acc = 0\n",
        "best_model_wts = copy.deepcopy(model.state_dict())\n",
        "patience_counter = 0\n",
        "early_stop_patience = 5\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    avg_train_loss = running_loss / len(train_loader)\n",
        "    train_losses.append(avg_train_loss)\n",
        "\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "    val_acc = 100 * correct / total\n",
        "    print(f\"Epoch {epoch+1}/{epochs} | \"\n",
        "    f\"Train Loss: {avg_train_loss:.4f} | \"\n",
        "    f\"Val Loss: {avg_val_loss:.4f} | \"\n",
        "    f\"Val Acc: {val_acc:.2f}%\")\n",
        "\n",
        "    scheduler.step(avg_val_loss)\n",
        "    print(f\"Current LR: {optimizer.param_groups[0]['lr']}\")\n",
        "\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        best_model_wts = copy.deepcopy(model.state_dict())\n",
        "        patience_counter = 0\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= early_stop_patience:\n",
        "            print(\"Early stopping triggered\")\n",
        "            break\n",
        "\n",
        "model.load_state_dict(best_model_wts)\n",
        "print(f\"Best Validation Accuracy: {best_val_acc:.2f}%\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "weather-classification",
      "language": "python",
      "name": "weather-classification"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
