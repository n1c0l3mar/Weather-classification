{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Model Attempt #2**"
      ],
      "metadata": {
        "id": "XA59Ew7FaYdj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Improvments To Be Made:\n",
        "\n",
        "Data Augmentation- RandomHorizontalFlip, RandomRotation, ColorJitter\n",
        "\n",
        "Make Image BIGGER- 64×64 to 128×128\n",
        "\n",
        "CNN Update- Add BatchNorm2d after conv layers\n",
        "\n",
        "Dropout- added 0.5 before final fully connected layer\n",
        "\n",
        "Learning Rate Scheduler- ReduceLROnPlateau\n",
        "\n",
        "Lengthen Training and Early Stopping- stop if no improvement in 5 epochs"
      ],
      "metadata": {
        "id": "i2AR2nZiaf-w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets, transforms, models\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import random\n",
        "import shutil\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib.image import imread\n",
        "import os\n",
        "from imageio import imread\n",
        "\n",
        "# Stop warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "#!unzip /content/drive/MyDrive/dataset.zip -d /content/dataset\n",
        "#path = '/content/dataset/dataset'\n"
      ],
      "metadata": {
        "id": "cvjysLNQc4kV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "width = []\n",
        "height = []\n",
        "channel_color = []\n",
        "weather_type = []\n",
        "\n",
        "path = '/content/dataset/dataset'\n",
        "\n",
        "# for each subfolder (category)\n",
        "for folder in os.listdir(path):\n",
        "    subfolder_path = os.path.join(path, folder_name)\n",
        "\n",
        "    # skip if not a directory\n",
        "    if not os.path.isdir(subfolder_path):\n",
        "        continue\n",
        "\n",
        "    for image_file in os.listdir(subfolder_path):\n",
        "        image_path = os.path.join(subfolder_path, image_file)\n",
        "\n",
        "        # skip directories inside category folders\n",
        "        if os.path.isdir(image_path):\n",
        "            continue\n",
        "\n",
        "        image = imread(image_path)\n",
        "\n",
        "        # handle grayscale images\n",
        "        if len(image.shape) < 3:\n",
        "            image = image.reshape(image.shape + (1,))\n",
        "\n",
        "        height, width, channel = image.shape\n",
        "        width.append(width)      # width on x-axis\n",
        "        height.append(height)     # height on y-axis\n",
        "        channel_color.append(channel)\n",
        "        weather_type.append(folder_name)  # use folder name as label\n",
        "\n",
        "# create DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'width': width,\n",
        "    'height': height,\n",
        "    'channels': channel_color,\n",
        "    'weather': weather_type\n",
        "})\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "ePK__z_Hc_yc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model"
      ],
      "metadata": {
        "id": "kzQrlHzxdF8i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import random_split, DataLoader\n",
        "from collections import Counter\n",
        "import copy\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# Data augmentation\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),  # larger image size\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5,0.5,0.5], std=[0.5,0.5,0.5])\n",
        "])\n",
        "\n",
        "\n",
        "# Load dataset\n",
        "dataset = datasets.ImageFolder('/content/dataset/dataset', transform=transform)\n",
        "num_classes = len(dataset.classes)\n",
        "print(\"Classes:\", dataset.classes)\n",
        "\n",
        "# Optional: check number of images per class\n",
        "labels = [label for _, label in dataset]\n",
        "counts = Counter(labels)\n",
        "print(\"Images per class:\", counts)\n",
        "\n",
        "# Train/Validation split\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32)\n",
        "\n",
        "# Define CNN with BatchNorm and Dropout\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(32)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc1 = nn.Linear(32 * 32 * 32, 128)  # adjusted for 128x128 input\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "        x = x.view(-1, 32 * 32 * 32)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = SimpleCNN(num_classes).to(device)\n",
        "\n",
        "# Loss & optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "# Learning rate scheduler (without verbose)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
        "\n",
        "# Training loop with early stopping\n",
        "epochs = 20\n",
        "best_val_acc = 0\n",
        "best_model_wts = copy.deepcopy(model.state_dict())\n",
        "patience_counter = 0\n",
        "early_stop_patience = 5\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # Training\n",
        "    model.train()\n",
        "    running_loss = 0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    avg_train_loss = running_loss / len(train_loader)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "    val_acc = 100 * correct / total\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
        "\n",
        "    # Step scheduler and print current LR\n",
        "    scheduler.step(avg_val_loss)\n",
        "    print(f\"Current LR: {optimizer.param_groups[0]['lr']}\")\n",
        "\n",
        "    # Early stopping\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        best_model_wts = copy.deepcopy(model.state_dict())\n",
        "        patience_counter = 0\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= early_stop_patience:\n",
        "            print(\"Early stopping triggered\")\n",
        "            break\n",
        "\n",
        "# Load best weights\n",
        "model.load_state_dict(best_model_wts)\n",
        "print(f\"Best Validation Accuracy: {best_val_acc:.2f}%\")\n"
      ],
      "metadata": {
        "id": "e17Lb_wLagkk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}